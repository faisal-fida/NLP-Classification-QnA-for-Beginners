{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5428cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f85892",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "  'How to be a good machine learning engineer',\n",
    "  'Top 10 skills for a successful machine learning career',\n",
    "  'The importance of continuous learning in machine learning',\n",
    "  'How to improve your machine learning model performance',\n",
    "  'The role of data visualization in machine learning',\n",
    "  'How to choose the right machine learning algorithm for your problem',\n",
    "  'The basics of deep learning and neural networks',\n",
    "  'How to prepare your data for machine learning',\n",
    "  'The importance of feature engineering in machine learning',\n",
    "  'Common pitfalls to avoid in machine learning'\n",
    "]\n",
    "\n",
    "# Choose the model hyperparameters\n",
    "batch_size = 128\n",
    "seq_length = 10\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7622699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the texts\n",
    "texts = [text.lower() for text in texts]\n",
    "texts = [re.sub(r'[^a-zA-Z0-9\\s]', '', text) for text in texts]\n",
    "\n",
    "# Create the vocabulary\n",
    "vocab = set()\n",
    "for text in texts:\n",
    "    vocab.update(text.split())\n",
    "vocab = {token: index for index, token in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Convert the texts to sequences of word indices\n",
    "sequences = []\n",
    "for text in texts:\n",
    "    sequence = [vocab[token] for token in text.split()]\n",
    "    sequences.append(sequence)\n",
    "\n",
    "# Split the sequences into training and validation sets\n",
    "x_train, x_val = train_test_split(sequences, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2c2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new texts\n",
    "def generate_text(model, prompt, num_words):\n",
    "    prompt_tokens = prompt.split()\n",
    "    input_tokens = prompt_tokens[-seq_length:]\n",
    "    input_indices = [vocab[token] for token in input_tokens]\n",
    "    input_indices = np.expand_dims(input_indices, axis=0)\n",
    "    generated_tokens = []\n",
    "    for _ in range(num_words):\n",
    "        probs = model.predict(input_indices)[0,-1,:]\n",
    "        index = np.random.choice(len(vocab), p=probs)\n",
    "        generated_tokens.append(vocab[index])\n",
    "        input_indices = np.concatenate([input_indices, np.expand_dims(index, axis=1)], axis=1)\n",
    "    return ' '.join(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe84db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 words based on a prompt\n",
    "prompt = 'How to be a good machine learning engineer'\n",
    "generated_text = generate_text(model, prompt, 10)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
